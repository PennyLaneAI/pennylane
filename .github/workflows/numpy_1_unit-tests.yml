name: NumPy 1 - Unit Tests - Interfaces
on:
  workflow_call:
    secrets:
      codecov_token:
        description: The codecov token to use when uploading coverage files
        required: true
    inputs:
      branch:
        description: The PennyLane branch to checkout and run unit tests for
        required: true
        type: string
      pipeline_mode:
          description: The pipeline mode can be unit-tests, benchmarks, or reference-benchmarks
          required: false
          type: string
          default: 'unit-tests'
      pytest_coverage_flags:
        description: PyTest Coverage flags to pass to all jobs
        required: false
        type: string
        default: --cov=pennylane --cov-append --cov-report=term-missing --cov-report=xml --no-flaky-report --tb=native
      disable_new_opmath:
        description: Whether to disable the new op_math or not when running the tests
        required: false
        type: string
        default: "False"

jobs:
  setup-ci-load:
    runs-on: ubuntu-latest

    steps:
      - name: Setup Python Versions
        id: python_versions

        # All jobs will use the 'default' python versions listed in the dictionary below.
        # Unless the job name exists as a key as well, in which case the python versions listed for the job itself will be used instead.
        run: |
            cat >python_versions.json <<-EOF
            {
                "default": ["3.10", "3.11", "3.12"],
                "torch-tests": ["3.10", "3.12"],
                "jax-tests": ["3.10", "3.12"],
                "external-libraries-tests": ["3.10"],
                "data-tests": ["3.10"],
            }
            EOF
        
            jq . python_versions.json
            echo "python_versions=$(jq -r tostring python_versions.json)" >> $GITHUB_OUTPUT

      - name: Setup Matrix Max Parallel
        id: max_parallel
        run: |
            cat >matrix_max_parallel.json <<-EOF
            {
                "default": 1,
                "core-tests": 5,
                "jax-tests": 10,
                "torch-tests": 2,
            }
            EOF

            jq . matrix_max_parallel.json
            echo "matrix_max_parallel=$(jq -r tostring matrix_max_parallel.json)" >> $GITHUB_OUTPUT

    outputs:
      matrix-max-parallel: ${{ steps.max_parallel.outputs.matrix_max_parallel }}
      python-version: ${{ steps.python_versions.outputs.python_versions }}

  torch-tests:
    needs:
      - setup-ci-load
    strategy:
      max-parallel: >-
        ${{
           fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).torch-tests
           || fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).default
         }}
      matrix:
        python-version: >-
          ${{
            fromJSON(needs.setup-ci-load.outputs.python-version).torch-tests
            || fromJSON(needs.setup-ci-load.outputs.python-version).default
           }}
        numpy-1-install: [true]
    uses: ./.github/workflows/unit-test.yml
    with:
      job_name: torch-tests (${{ matrix.python-version }}, numpy-1.26)
      branch: ${{ inputs.branch }}
      coverage_artifact_name: core-interfaces-coverage-torch-${{ matrix.python-version }}-numpy-1.26
      python_version: ${{ matrix.python-version }}
      pipeline_mode: ${{ inputs.pipeline_mode }}
      install_numpy_1: ${{ matrix.numpy-1-install }}
      install_jax: false
      install_tensorflow: false
      install_pytorch: true
      install_pennylane_lightning_master: true
      pytest_coverage_flags: ${{ inputs.pytest_coverage_flags }}
      pytest_markers: torch and not qcut and not finite-diff and not param-shift
      requirements_file: ${{ github.event_name == 'schedule' && strategy.job-index == 0 && 'torch.txt' || '' }}
      disable_new_opmath: ${{ inputs.disable_new_opmath }}


  autograd-tests:
    needs:
      - setup-ci-load
    strategy:
      max-parallel: >-
        ${{
           fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).autograd-tests
           || fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).default
         }}
      matrix:
        python-version: >-
          ${{
            fromJSON(needs.setup-ci-load.outputs.python-version).autograd-tests
            || fromJSON(needs.setup-ci-load.outputs.python-version).default
           }}
        numpy-1-install: [true]
    uses: ./.github/workflows/unit-test.yml
    with:
      job_name: autograd-tests (${{ matrix.python-version }}, numpy-1.26)
      branch: ${{ inputs.branch }}
      coverage_artifact_name: core-interfaces-coverage-autograd-${{ matrix.python-version }}-numpy-1.26
      python_version: ${{ matrix.python-version }}
      pipeline_mode: ${{ inputs.pipeline_mode }}
      install_numpy_1: ${{ matrix.numpy-1-install }}
      install_jax: false
      install_tensorflow: false
      install_pytorch: false
      install_pennylane_lightning_master: true
      pytest_coverage_flags: ${{ inputs.pytest_coverage_flags }}
      pytest_markers: autograd and not qcut and not finite-diff and not param-shift
      disable_new_opmath: ${{ inputs.disable_new_opmath }}


  jax-tests:
    needs:
      - setup-ci-load
    strategy:
      max-parallel: >-
        ${{
           fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).jax-tests
           || fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).default
         }}
      matrix:
        group: [1, 2, 3, 4, 5]
        python-version: >-
          ${{
            fromJSON(needs.setup-ci-load.outputs.python-version).jax-tests
            || fromJSON(needs.setup-ci-load.outputs.python-version).default
           }}
        numpy-1-install: [true]
    uses: ./.github/workflows/unit-test.yml
    with:
      job_name: jax-tests (${{ matrix.group }}, ${{ matrix.python-version }}, numpy-1.26)
      branch: ${{ inputs.branch }}
      coverage_artifact_name: core-interfaces-coverage-jax-${{ matrix.python-version }}-${{ matrix.group }}-numpy-1.26
      python_version: ${{ matrix.python-version }}
      pipeline_mode: ${{ inputs.pipeline_mode }}
      install_numpy_1: ${{ matrix.numpy-1-install }}
      install_jax: true
      install_tensorflow: false
      install_pytorch: false
      install_pennylane_lightning_master: true
      pytest_coverage_flags: ${{ inputs.pytest_coverage_flags }}
      pytest_markers: jax and not qcut and not finite-diff and not param-shift
      pytest_additional_args: --splits 5 --group ${{ matrix.group }}
      additional_pip_packages: pytest-split
      requirements_file: ${{ github.event_name == 'schedule' && strategy.job-index == 0 && 'jax.txt' || '' }}
      disable_new_opmath: ${{ inputs.disable_new_opmath }}


  core-tests:
    needs:
      - setup-ci-load
    strategy:
      max-parallel: >-
        ${{
           fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).core-tests
           || fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).default
         }}
      matrix:
        group: [1, 2, 3, 4, 5]
        python-version: >-
          ${{
            fromJSON(needs.setup-ci-load.outputs.python-version).core-tests
            || fromJSON(needs.setup-ci-load.outputs.python-version).default
           }}
        numpy-1-install: [true]
    uses: ./.github/workflows/unit-test.yml
    with:
      job_name: core-tests (${{ matrix.group }}, ${{ matrix.python-version }}, numpy-1.26)
      branch: ${{ inputs.branch }}
      coverage_artifact_name: core-interfaces-coverage-core-${{ matrix.python-version }}-${{ matrix.group }}-numpy-1.26
      python_version: ${{ matrix.python-version }}
      pipeline_mode: ${{ inputs.pipeline_mode }}
      install_numpy_1: ${{ matrix.numpy-1-install }}
      install_jax: false
      install_tensorflow: false
      install_pytorch: false
      install_pennylane_lightning_master: true
      pytest_coverage_flags: ${{ inputs.pytest_coverage_flags }}
      pytest_markers: core and not qcut and not finite-diff and not param-shift
      pytest_additional_args: --splits 5 --group ${{ matrix.group }}
      additional_pip_packages: pytest-split
      requirements_file: ${{ github.event_name == 'schedule' && strategy.job-index == 0 && 'core.txt' || '' }}
      disable_new_opmath: ${{ inputs.disable_new_opmath }}


  data-tests:
    needs:
      - setup-ci-load
    strategy:
      max-parallel: >-
        ${{
           fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).data-tests
           || fromJSON(needs.setup-ci-load.outputs.matrix-max-parallel).default
         }}
      matrix:
        python-version: >-
          ${{
            fromJSON(needs.setup-ci-load.outputs.python-version).data-tests
            || fromJSON(needs.setup-ci-load.outputs.python-version).default
           }}
        numpy-1-install: [true]
    uses: ./.github/workflows/unit-test.yml
    with:
      job_name: data-tests (${{ matrix.python-version }}, numpy-1.26)
      branch: ${{ inputs.branch }}
      coverage_artifact_name: data-coverage-${{ matrix.python-version }}-numpy-1.26
      python_version: ${{ matrix.python-version }}
      pipeline_mode: ${{ inputs.pipeline_mode }}
      install_numpy_1: ${{ matrix.numpy-1-install }}
      install_jax: false
      install_tensorflow: false
      install_pytorch: false
      install_pennylane_lightning_master: true
      pytest_coverage_flags: ${{ inputs.pytest_coverage_flags }}
      pytest_markers: data
      additional_pip_packages: h5py
      disable_new_opmath: ${{ inputs.disable_new_opmath }}


  upload-to-codecov:
    runs-on: ubuntu-latest

    needs:
      - torch-tests
      - autograd-tests
      - jax-tests
      - core-tests
      - data-tests

    # Run this even if any of the above jobs are skipped but not if any of the jobs failed
    if: >-
      ${{
        always() &&
        !contains(needs.*.result, 'failure') &&
        !contains(needs.*.result, 'cancelled') &&
        inputs.pipeline_mode == 'unit-tests'
       }}

    steps:
      # Checkout repo so Codecov action is able to resolve git HEAD reference
      - name: Checkout
        uses: actions/checkout@v3
        with:
          ref: ${{ inputs.branch }}

      - name: Down Coverage Artifacts
        uses: actions/download-artifact@v4

      - name: Upload to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.codecov_token }}
          fail_ci_if_error: true  # upload errors should be caught early
