{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Variational quantum eigensolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial showcases a simplified variational quantum eigensolver (Peruzzo et al 2014). Using the hybrid principle of openqml, we first train a quantum circuit to minimize the energy expectation for a Hamiltonian\n",
    "\n",
    "$$ \\langle \\psi | H | \\psi \\rangle  = 0.1 \\langle \\psi_{w} | X | \\psi_w \\rangle + 0.5 \\langle \\psi_w | Y | \\psi_w \\rangle.  $$\n",
    "\n",
    "Here, $| \\psi_w \\rangle $ is the state after applying the quantum circuit which depends on trainable weights $w$, and $X$, $Y$ denote the Pauli-X and Pauli-Y operator. \n",
    "\n",
    "We then turn things around and use a fixed quantum circuit to prepare $| \\psi \\rangle $, but train the coefficients of the Hamiltonian to minimize\n",
    "\n",
    "$$ \\langle \\psi | H | \\psi \\rangle  = w_0 \\langle \\psi | X | \\psi \\rangle + w_1 \\langle \\psi | Y | \\psi \\rangle . $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alongside the openqml framework, we import the standard gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:54:57 WARNING No OpenQML configuration file found.\n"
     ]
    }
   ],
   "source": [
    "import openqml as qm\n",
    "from openqml import numpy as np\n",
    "from openqml._optimize import GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In this tutorial we use the projectq simulator. For this to work, you need to install the projectq plugin. DETAILS!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev = qm.device('projectq.simulator', wires=2)\n",
    "dev = qm.device('default.qubit', wires=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantum circuit of the variational eigensolver is an ansatz that defines a manifold of possible quantum states. We use a \"hardcoded\" initial superposition, together with two rotations and a CNOT gate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz(weights):\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(weights[0], [0])\n",
    "    qm.RY(weights[1], [1])\n",
    "    qm.CNOT([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variational eigensolvers requires us to evaluate expectations of different Pauli operators. In this example, the Hamiltonian is expressed by only two single-qubit Pauli operators, namely the X and Y operator applied to the first qubit. \n",
    "\n",
    "Since these operators do not commute, we need two quantum functions, but they can reuse the same device we created. \n",
    "\n",
    "*NOTE: If the Pauli observables referred to different qubits, we could use one quantum function and return a tuple of expectations:*\n",
    "\n",
    "*return (qm.expectation.PauliX(0), qm.expectation.PauliX(1))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qm.qfunc(dev)\n",
    "def circuit_X(weights):\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y(weights):\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliY(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of a VQE, often called a \"cost\", is simply a linear combination of the expectations, which defines the expectation of the Hamiltonian we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights):\n",
    "    expX = circuit_X(weights)\n",
    "    expY = circuit_Y(weights)\n",
    "    return 0.1*expX + 0.5*expY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cost defines the following landscape:\n",
    " <img src=\"figures/vqe_q_landscape.png\" width=\"450\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the gradient descent optimizer from Tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0.]\n",
      "Cost after step     1: -0.1414948\n",
      "Cost after step     2: -0.2829897\n",
      "Cost after step     3: -0.4244845\n",
      "Cost after step     4: -0.5659793\n",
      "Cost after step     5: -0.7074741\n",
      "Cost after step     6: -0.8489690\n",
      "Cost after step     7: -0.9904638\n",
      "Cost after step     8: -1.1319586\n",
      "Cost after step     9: -1.2734534\n",
      "Cost after step    10: -1.4149483\n",
      "Cost after step    11: -1.5564431\n",
      "Cost after step    12: -1.6979379\n",
      "Cost after step    13: -1.8394327\n",
      "Cost after step    14: -1.9809276\n",
      "Cost after step    15: -2.1224224\n",
      "Cost after step    16: -2.2639172\n",
      "Cost after step    17: -2.4054121\n",
      "Cost after step    18: -2.5469069\n",
      "Cost after step    19: -2.6884017\n",
      "Cost after step    20: -2.8298965\n",
      "Optimized weights: [-4.25246528 -3.19617026]\n"
     ]
    }
   ],
   "source": [
    "weights0 = np.array([0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {:5d}: {:0.7f}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"figures/vqe_q_landscape_gd.png\" width=\"450\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Hamiltonian coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of optimizing the circuit parameter, we can also use a fixed circuit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz():\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(-0.5, [0])\n",
    "    qm.RY( 0.5, [1])\n",
    "    qm.CNOT([0, 1])\n",
    "    \n",
    "    \n",
    "@qm.qfunc(dev)\n",
    "def circuit_X():\n",
    "    ansatz()\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y():\n",
    "    ansatz()\n",
    "    return qm.expectation.PauliY(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and make the classical coefficients trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights):\n",
    "    expX = circuit_X()\n",
    "    expY = circuit_Y()\n",
    "    return weights[0]*expX + weights[1]*expY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization landscape becomes nearly linear (since smaller coefficients decreas the energy expectation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0.]\n",
      "Cost after step     1: -0.1414948\n",
      "Cost after step     2: -0.2829897\n",
      "Cost after step     3: -0.4244845\n",
      "Cost after step     4: -0.5659793\n",
      "Cost after step     5: -0.7074741\n",
      "Cost after step     6: -0.8489690\n",
      "Cost after step     7: -0.9904638\n",
      "Cost after step     8: -1.1319586\n",
      "Cost after step     9: -1.2734534\n",
      "Cost after step    10: -1.4149483\n",
      "Cost after step    11: -1.5564431\n",
      "Cost after step    12: -1.6979379\n",
      "Cost after step    13: -1.8394327\n",
      "Cost after step    14: -1.9809276\n",
      "Cost after step    15: -2.1224224\n",
      "Cost after step    16: -2.2639172\n",
      "Cost after step    17: -2.4054121\n",
      "Cost after step    18: -2.5469069\n",
      "Cost after step    19: -2.6884017\n",
      "Cost after step    20: -2.8298965\n",
      "Optimized weights: [-4.25246528 -3.19617026]\n"
     ]
    }
   ],
   "source": [
    "weights0 = np.array([0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {:5d}: {:0.7f}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"figures/vqe_c_landscape_gd.png\" width=\"450\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing classical and quantum parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also optimize \"classical\" and \"quantum\" weights together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0. 0. 0.]\n",
      "Cost after step     1: -0.2007100\n",
      "Cost after step     2: -0.3559911\n",
      "Cost after step     3: -0.4438553\n",
      "Cost after step     4: -0.4245009\n",
      "Cost after step     5: -0.3434856\n",
      "Cost after step     6: -0.3495459\n",
      "Cost after step     7: -0.5480820\n",
      "Cost after step     8: -0.9117063\n",
      "Cost after step     9: -1.3625706\n",
      "Cost after step    10: -1.8478475\n",
      "Cost after step    11: -2.3443760\n",
      "Cost after step    12: -2.8440060\n",
      "Cost after step    13: -3.3442674\n",
      "Cost after step    14: -3.8445344\n",
      "Cost after step    15: -4.3447054\n",
      "Cost after step    16: -4.8447993\n",
      "Cost after step    17: -5.3448469\n",
      "Cost after step    18: -5.8448700\n",
      "Cost after step    19: -6.3448809\n",
      "Cost after step    20: -6.8448859\n",
      "Optimized weights: [1.57008454 2.67634249 3.95493043 5.84558939]\n"
     ]
    }
   ],
   "source": [
    "def ansatz(weights):\n",
    "    \"\"\" Ansatz of the variational circuit.\"\"\"\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(weights[0], [0])\n",
    "    qm.RY(weights[1], [1])\n",
    "    qm.CNOT([0, 1])\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_X(weights):\n",
    "    \"\"\"Circuit measuring the X operator\"\"\"\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y(weights):\n",
    "    \"\"\"Circuit measuring the Y operator\"\"\"\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliY(1)\n",
    "\n",
    "\n",
    "def cost(weights):\n",
    "    \"\"\"Cost (error) function to be minimized.\"\"\"\n",
    "\n",
    "    expX = circuit_X(weights[0:2])\n",
    "    expY = circuit_Y(weights[0:2])\n",
    "\n",
    "    return weights[2]*expX + weights[3]*expY\n",
    "\n",
    "weights0 = np.array([0., 0., 0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {:5d}: {:0.7f}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Visualisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
