{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Variational quantum eigensolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial showcases a simplified variational quantum eigensolver (Peruzzo et al 2014). Using the hybrid principle of openqml, we first train a quantum circuit to minimize the energy expectation for a Hamiltonian\n",
    "\n",
    "$$ \\langle \\psi | H | \\psi \\rangle  = 0.1 \\langle \\psi_{w} | X | \\psi_w \\rangle + 0.5 \\langle \\psi_w | Y | \\psi_w \\rangle.  $$\n",
    "\n",
    "Here, $| \\psi_w \\rangle $ is the state after applying the quantum circuit which depends on trainable weights $w$, and $X$, $Y$ denote the Pauli-X and Pauli-Y operator. \n",
    "\n",
    "We then turn things around and use a fixed quantum circuit to prepare $| \\psi \\rangle $, but train the coefficients of the Hamiltonian to minimize\n",
    "\n",
    "$$ \\langle \\psi | H | \\psi \\rangle  = w_0 \\langle \\psi | X | \\psi \\rangle + w_1 \\langle \\psi | Y | \\psi \\rangle . $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alongside the openqml framework, we import the standard gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:32:35 WARNING No OpenQML configuration file found.\n"
     ]
    }
   ],
   "source": [
    "import openqml as qm\n",
    "from openqml import numpy as np\n",
    "from openqml._optimize import GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In this tutorial we use the projectq simulator. For this to work, you need to install the projectq plugin. DETAILS!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev = qm.device('projectq.simulator', wires=2)\n",
    "dev = qm.device('default.qubit', wires=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantum circuit of the variational eigensolver is an ansatz that defines a manifold of possible quantum states. We use a \"hardcoded\" initial superposition, together with two rotations and a CNOT gate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz(weights):\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(weights[0], [0])\n",
    "    qm.RY(weights[1], [1])\n",
    "    qm.CNOT([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variational eigensolvers requires us to evaluate expectations of different Pauli operators. In this example, the Hamiltonian is expressed by only two single-qubit Pauli operators, namely the X and Y operator applied to the first qubit. \n",
    "\n",
    "Since these operators do not commute, we need two quantum functions, but they can reuse the same device we created. \n",
    "\n",
    "*NOTE: If the Pauli observables referred to different qubits, we could use one quantum function and return a tuple of expectations:*\n",
    "\n",
    "*return (qm.expectation.PauliX(0), qm.expectation.PauliX(1))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qm.qfunc(dev)\n",
    "def circuit_X(weights):\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y(weights):\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliY(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of a VQE, often called a \"cost\", is simply a linear combination of the expectations, which defines the expectation of the Hamiltonian we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights):\n",
    "    expX = circuit_X(weights)\n",
    "    expY = circuit_Y(weights)\n",
    "    return 0.1*expX + 0.5*expY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cost defines the following landscape:\n",
    " <img src=\"figures/vqe_q_landscape.png\" width=\"450\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the gradient descent optimizer from Tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0 0]\n",
      "Cost after step 1: -0.04885188791763629\n",
      "Cost after step 2: -0.1520885316363529\n",
      "Cost after step 3: -0.23218318322576306\n",
      "Cost after step 4: -0.2919525276178529\n",
      "Cost after step 5: -0.3373750061482431\n",
      "Cost after step 6: -0.3699464440518563\n",
      "Cost after step 7: -0.3898312213146038\n",
      "Cost after step 8: -0.39999850098567463\n",
      "Cost after step 9: -0.40458706512442877\n",
      "Cost after step 10: -0.4065264820730262\n",
      "Cost after step 11: -0.4073233352760281\n",
      "Cost after step 12: -0.4076473963003147\n",
      "Cost after step 13: -0.40777885323170654\n",
      "Cost after step 14: -0.40783221689607096\n",
      "Cost after step 15: -0.40785392418492195\n",
      "Cost after step 16: -0.4078627781057823\n",
      "Cost after step 17: -0.40786640037292715\n",
      "Cost after step 18: -0.40786788710073507\n",
      "Cost after step 19: -0.4078684993870676\n",
      "Cost after step 20: -0.4078687524335624\n",
      "Optimized weights: [1.57008454 2.67634249]\n"
     ]
    }
   ],
   "source": [
    "weights0 = np.array([0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {}: {}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"figures/vqe_q_landscape_gd.png\" width=\"450\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Hamiltonian coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of optimizing the circuit parameter, we can also use a fixed circuit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz():\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(-0.5, [0])\n",
    "    qm.RY( 0.5, [1])\n",
    "    qm.CNOT([0, 1])\n",
    "    \n",
    "    \n",
    "@qm.qfunc(dev)\n",
    "def circuit_X():\n",
    "    ansatz()\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y():\n",
    "    ansatz()\n",
    "    return qm.expectation.PauliY(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and make the classical coefficients trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights):\n",
    "    expX = circuit_X()\n",
    "    expY = circuit_Y()\n",
    "    return weights[0]*expX + weights[1]*expY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization landscape becomes nearly linear (since smaller coefficients decreas the energy expectation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0.]\n",
      "Cost after step 1: -0.14149482652500764\n",
      "Cost after step 2: -0.2829896530500153\n",
      "Cost after step 3: -0.4244844795750229\n",
      "Cost after step 4: -0.5659793061000306\n",
      "Cost after step 5: -0.7074741326250382\n",
      "Cost after step 6: -0.8489689591500459\n",
      "Cost after step 7: -0.9904637856750537\n",
      "Cost after step 8: -1.1319586122000613\n",
      "Cost after step 9: -1.2734534387250689\n",
      "Cost after step 10: -1.4149482652500764\n",
      "Cost after step 11: -1.5564430917750842\n",
      "Cost after step 12: -1.697937918300092\n",
      "Cost after step 13: -1.8394327448250993\n",
      "Cost after step 14: -1.980927571350107\n",
      "Cost after step 15: -2.122422397875115\n",
      "Cost after step 16: -2.2639172244001227\n",
      "Cost after step 17: -2.40541205092513\n",
      "Cost after step 18: -2.5469068774501378\n",
      "Cost after step 19: -2.6884017039751456\n",
      "Cost after step 20: -2.829896530500153\n",
      "Optimized weights: [-4.25246528 -3.19617026]\n"
     ]
    }
   ],
   "source": [
    "weights0 = np.array([0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {}: {}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"figures/vqe_c_landscape_gd.png\" width=\"450\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing classical and quantum parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also optimize \"classical\" and \"quantum\" weights together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0. 0. 0.]\n",
      "Cost after step 1: -0.20071003671471505\n",
      "Cost after step 2: -0.3559910601990571\n",
      "Cost after step 3: -0.44385532443929593\n",
      "Cost after step 4: -0.4245009303474421\n",
      "Cost after step 5: -0.3434855527790233\n",
      "Cost after step 6: -0.3495459445408875\n",
      "Cost after step 7: -0.5480819865254716\n",
      "Cost after step 8: -0.9117062625485028\n",
      "Cost after step 9: -1.362570565807977\n",
      "Cost after step 10: -1.8478475065762556\n",
      "Cost after step 11: -2.344375985260513\n",
      "Cost after step 12: -2.8440059819458843\n",
      "Cost after step 13: -3.344267418902312\n",
      "Cost after step 14: -3.8445343585156877\n",
      "Cost after step 15: -4.344705380002273\n",
      "Cost after step 16: -4.844799254556266\n",
      "Cost after step 17: -5.344846931898632\n",
      "Cost after step 18: -5.8448700467900725\n",
      "Cost after step 19: -6.344880914960131\n",
      "Cost after step 20: -6.844885916292804\n",
      "Optimized weights: [1.57008454 2.67634249 3.95493043 5.84558939]\n"
     ]
    }
   ],
   "source": [
    "def ansatz(weights):\n",
    "    \"\"\" Ansatz of the variational circuit.\"\"\"\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(weights[0], [0])\n",
    "    qm.RY(weights[1], [1])\n",
    "    qm.CNOT([0, 1])\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_X(weights):\n",
    "    \"\"\"Circuit measuring the X operator\"\"\"\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y(weights):\n",
    "    \"\"\"Circuit measuring the Y operator\"\"\"\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliY(1)\n",
    "\n",
    "\n",
    "def cost(weights):\n",
    "    \"\"\"Cost (error) function to be minimized.\"\"\"\n",
    "\n",
    "    expX = circuit_X(weights[0:2])\n",
    "    expY = circuit_Y(weights[0:2])\n",
    "\n",
    "    return weights[2]*expX + weights[3]*expY\n",
    "\n",
    "weights0 = np.array([0., 0., 0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {}: {}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Visualisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
