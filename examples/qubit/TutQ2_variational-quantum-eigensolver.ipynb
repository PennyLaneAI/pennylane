{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Q2 - Variational quantum eigensolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates a simplified variational quantum eigensolver (Peruzzo et al 2014). To showcase the hybrid principle of openqml, we first train a quantum circuit to minimize the energy expectation for a Hamiltonian $H$, \n",
    "\n",
    "$$ \\langle \\psi | H | \\psi \\rangle  = 0.1 \\langle \\psi_{w} | X_2 | \\psi_w \\rangle + 0.5 \\langle \\psi_w | Y_2 | \\psi_w \\rangle.  $$\n",
    "\n",
    "Here, $| \\psi_w \\rangle $ is the state after applying the quantum circuit which depends on trainable weights $w = \\{w_1, w_2\\}$, and $X_2$, $Y_2$ denote the Pauli-X and Pauli-Y operator acting on the second qubit. \n",
    "\n",
    "We then turn things around and use a fixed quantum circuit to prepare $| \\psi \\rangle $, but train the coefficients of the Hamiltonian to minimize\n",
    "\n",
    "$$ \\langle \\psi | H | \\psi \\rangle  = w_0 \\langle \\psi | X_2 | \\psi \\rangle + w_1 \\langle \\psi | Y_2 | \\psi \\rangle . $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Optimize the quantum circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alongside the openqml framework, as well as the openqml and original numpy library, we import the standard gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:59:19 WARNING No OpenQML configuration file found.\n"
     ]
    }
   ],
   "source": [
    "import openqml as qm\n",
    "from openqml import numpy as onp\n",
    "import numpy as np\n",
    "from openqml._optimize import GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In this tutorial we use the projectq simulator. For this to work, you need to install the projectq plugin. DETAILS!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev = qm.device('projectq.simulator', wires=2)\n",
    "dev = qm.device('default.qubit', wires=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantum circuit of the variational eigensolver is an ansatz that defines a manifold of possible quantum states. We use a \"hardcoded\" initial superposition, together with two rotations and a CNOT gate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz(weights):\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(weights[0], [0])\n",
    "    qm.RY(weights[1], [1])\n",
    "    qm.CNOT([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variational eigensolvers requires us to evaluate expectations of different Pauli operators. In this example, the Hamiltonian is expressed by only two single-qubit Pauli operators, namely the X and Y operator applied to the first qubit. \n",
    "\n",
    "Since these operators do not commute, we need two quantum functions, but they can reuse the same device we created. \n",
    "\n",
    "*NOTE: If the Pauli observables referred to different qubits, we could use one quantum function and return a tuple of expectations:*\n",
    "\n",
    "*return (qm.expectation.PauliX(0), qm.expectation.PauliX(1))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qm.qfunc(dev)\n",
    "def circuit_X(weights):\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y(weights):\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliY(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of a VQE, usually called a \"cost\", is simply a linear combination of the expectations, which defines the expectation of the Hamiltonian we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights):\n",
    "    expX = circuit_X(weights)\n",
    "    expY = circuit_Y(weights)\n",
    "    return 0.1*expX + 0.5*expY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cost defines the following landscape:\n",
    " <img src=\"figures/vqe_q_landscape.png\" width=\"450\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the gradient descent optimizer from Tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0.]\n",
      "Cost after step     1: -0.0488519\n",
      "Cost after step     2: -0.1520885\n",
      "Cost after step     3: -0.2321832\n",
      "Cost after step     4: -0.2919525\n",
      "Cost after step     5: -0.3373750\n",
      "Cost after step     6: -0.3699464\n",
      "Cost after step     7: -0.3898312\n",
      "Cost after step     8: -0.3999985\n",
      "Cost after step     9: -0.4045871\n",
      "Cost after step    10: -0.4065265\n",
      "Cost after step    11: -0.4073233\n",
      "Cost after step    12: -0.4076474\n",
      "Cost after step    13: -0.4077789\n",
      "Cost after step    14: -0.4078322\n",
      "Cost after step    15: -0.4078539\n",
      "Cost after step    16: -0.4078628\n",
      "Cost after step    17: -0.4078664\n",
      "Cost after step    18: -0.4078679\n",
      "Cost after step    19: -0.4078685\n",
      "Cost after step    20: -0.4078688\n",
      "Optimized weights: [1.57008454 2.67634249]\n"
     ]
    }
   ],
   "source": [
    "weights0 = np.array([0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {:5d}: {: 0.7f}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"figures/vqe_q_landscape_gd.png\" width=\"450\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimizing the Hamiltonian coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of optimizing the circuit parameter, we can also use a fixed circuit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz():\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(-0.5, [0])\n",
    "    qm.RY( 0.5, [1])\n",
    "    qm.CNOT([0, 1])\n",
    "    \n",
    "    \n",
    "@qm.qfunc(dev)\n",
    "def circuit_X():\n",
    "    ansatz()\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y():\n",
    "    ansatz()\n",
    "    return qm.expectation.PauliY(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and make the classical coefficients trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights):\n",
    "    expX = circuit_X()\n",
    "    expY = circuit_Y()\n",
    "    return weights[0]*expX + weights[1]*expY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this cost, ever smaller coefficients decrease the energy expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [1. 1.]\n",
      "Cost after step     1:  0.6033687\n",
      "Cost after step     2:  0.4618739\n",
      "Cost after step     3:  0.3203791\n",
      "Cost after step     4:  0.1788842\n",
      "Cost after step     5:  0.0373894\n",
      "Cost after step     6: -0.1041054\n",
      "Cost after step     7: -0.2456002\n",
      "Cost after step     8: -0.3870951\n",
      "Cost after step     9: -0.5285899\n",
      "Cost after step    10: -0.6700847\n",
      "Cost after step    11: -0.8115795\n",
      "Cost after step    12: -0.9530744\n",
      "Cost after step    13: -1.0945692\n",
      "Cost after step    14: -1.2360640\n",
      "Cost after step    15: -1.3775588\n",
      "Cost after step    16: -1.5190537\n",
      "Cost after step    17: -1.6605485\n",
      "Cost after step    18: -1.8020433\n",
      "Cost after step    19: -1.9435381\n",
      "Cost after step    20: -2.0850330\n",
      "Optimized weights: [-3.25246528 -2.19617026]\n"
     ]
    }
   ],
   "source": [
    "weights0 = np.array([1., 1.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in range(20):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {:5d}: {: 0.7f}'.format(iteration+1, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the optimization landscape is nearly linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"figures/vqe_c_landscape_gd.png\" width=\"450\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing classical and quantum parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also optimize \"classical\" and \"quantum\" weights together by combining the two approaches from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0. 0. 0.]\n",
      "Cost after step     1: -0.2007100\n",
      "Cost after step     2: -0.3559911\n",
      "Cost after step     3: -0.4438553\n",
      "Cost after step     4: -0.4245009\n",
      "Cost after step     5: -0.3434856\n",
      "Cost after step     6: -0.3495459\n",
      "Cost after step     7: -0.5480820\n",
      "Cost after step     8: -0.9117063\n",
      "Cost after step     9: -1.3625706\n",
      "Cost after step    10: -1.8478475\n",
      "Cost after step    11: -2.3443760\n",
      "Cost after step    12: -2.8440060\n",
      "Cost after step    13: -3.3442674\n",
      "Cost after step    14: -3.8445344\n",
      "Cost after step    15: -4.3447054\n",
      "Cost after step    16: -4.8447993\n",
      "Cost after step    17: -5.3448469\n",
      "Cost after step    18: -5.8448700\n",
      "Cost after step    19: -6.3448809\n",
      "Cost after step    20: -6.8448859\n",
      "Optimized weights: [1.57008454 2.67634249 3.95493043 5.84558939]\n"
     ]
    }
   ],
   "source": [
    "def ansatz(weights):\n",
    "    \"\"\" Ansatz of the variational circuit.\"\"\"\n",
    "\n",
    "    initial_state = np.array([1, 1, 0, 1])/np.sqrt(3)\n",
    "    qm.QubitStateVector(initial_state, wires=[0, 1])\n",
    "\n",
    "    qm.RX(weights[0], [0])\n",
    "    qm.RY(weights[1], [1])\n",
    "    qm.CNOT([0, 1])\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_X(weights):\n",
    "    \"\"\"Circuit measuring the X operator\"\"\"\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliX(1)\n",
    "\n",
    "\n",
    "@qm.qfunc(dev)\n",
    "def circuit_Y(weights):\n",
    "    \"\"\"Circuit measuring the Y operator\"\"\"\n",
    "    ansatz(weights)\n",
    "    return qm.expectation.PauliY(1)\n",
    "\n",
    "\n",
    "def cost(weights):\n",
    "    \"\"\"Cost (error) function to be minimized.\"\"\"\n",
    "\n",
    "    expX = circuit_X(weights[0:2])\n",
    "    expY = circuit_Y(weights[0:2])\n",
    "\n",
    "    return weights[2]*expX + weights[3]*expY\n",
    "\n",
    "weights0 = np.array([0., 0., 0., 0.])\n",
    "print('Initial weights:', weights0)\n",
    "\n",
    "o = GradientDescentOptimizer(0.5)\n",
    "weights = weights0\n",
    "for iteration in np.arange(1, 21):\n",
    "    weights = o.step(cost, weights)\n",
    "    print('Cost after step {:5d}: {: 0.7f}'.format(iteration, cost(weights)))\n",
    "print('Optimized weights:', weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
