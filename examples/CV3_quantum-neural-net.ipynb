{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example CV3 - Function fitting with a quantum neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we show how a variational circuit can be used to learn a fit for a one-dimensional function when being trained with noisy samples from that function. \n",
    "\n",
    "The variational circuit we use is the continuous-variable quantum neural network model described in [Killoran et al. (2018)](https://arxiv.org/abs/1806.06871). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import PennyLane, the wrapped version of NumPy provided by PennyLane, and an optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The device we use is the Strawberry Fields simulator, this time with only one quantum mode (or `wire`). You will need to have the Strawberry Fields plugin for PennyLane installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dev = qml.device('strawberryfields.fock', wires=1, cutoff_dim=10)    \n",
    "except:\n",
    "    print(\"To run this demo you need to install the strawberryfields plugin...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum node\n",
    "\n",
    "For a single quantum mode, each layer of the variational circuit is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(v):\n",
    "\n",
    "    # Matrix multiplication of input layer\n",
    "    qml.Rotation(v[0], wires=0)\n",
    "    qml.Squeezing(v[1], 0., wires=0)\n",
    "    qml.Rotation(v[2], wires=0)\n",
    "\n",
    "    # Bias\n",
    "    qml.Displacement(v[3], 0., wires=0)\n",
    "\n",
    "    # Element-wise nonlinear transformation\n",
    "    qml.Kerr(v[4], wires=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variational circuit in the quantum node first encodes the input into the displacement of the mode, and then executes the layers. The output is the expectation of the x-quadrature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def quantum_neural_net(var, x=None):\n",
    "    \n",
    "    # Encode input x into quantum state\n",
    "    qml.Displacement(x, 0., wires=0)\n",
    "\n",
    "    # \"layer\" subcircuits\n",
    "    for v in var:\n",
    "        layer(v)\n",
    "\n",
    "    return qml.expval.X(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an objective we take the square loss between target labels and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss += (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cost function, we compute the outputs from the variational circuit. Function fitting is a regression problem, and we interpret the expectations from the quantum node as predictions (i.e., without applying postprocessing such as thresholding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(var, features, labels):\n",
    "\n",
    "    preds = [quantum_neural_net(var, x=x) for x in features]\n",
    "\n",
    "    return square_loss(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load noisy data samples of a sine function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/sine.txt\")\n",
    "X = data[:, 0]\n",
    "Y = data[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, let's examine the data.\n",
    "\n",
    "*Note: For the next cell to work you need the matplotlib library.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEXCAYAAADiEjDuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHcRJREFUeJzt3X+UXGWd5/H3h6aBDrtOkwV06SE/EE8wWYSM7aCTVQM6\nm3EGMQLK7IAHGTUzznpWccgxrAwiMCbnxEHdmVUJq4srChyUE0BwcJaAwwHBDQaEeAiLgrgtzgaT\n8CtN6CTf/eNWkUp1VdevW1X33vq8zqnTqVv3qX7qUtxvP8/zfZ5HEYGZmVm/HdDvCpiZmYEDkpmZ\nZYQDkpmZZYIDkpmZZYIDkpmZZYIDkpmZZYIDkpmZZYIDkpmZZYIDkpmZZcKB/a5Anhx++OExb968\nflfDzCxXHnjggWci4ohG5zkgtWDevHls3Lix39UwM8sVSb9s5jx32ZmZWSY4IJmZWSY4IJmZWSY4\nIJmZWSY4IJmZWSY4IJmZWSY47dvMrGT9pgnW3r6FX++Y5KjREVYuW8DyxWP9rtbAcEAyMyMJRhfe\n+DCTU3sAmNgxyYU3PgzgoNQj7rIzMwPW3r7llWBUNjm1h7W3b+lTjQaPW0hmNhAadcf9esdkzXL1\njlv63EIys8Ird8dN7Jgk2Ncdt37TxCvnHDU6UrNsveOWPgckMyu8ZrrjVi5bwMjw0H7njAwPsXLZ\ngp7U0dxlZ2YDoJnuuHL3nbPs+scBycwK76jRESZqBKXq7rjli8ccgPrIXXZmVnjujssHt5DMrPDc\nHZcPDkhmNhDcHZd97rIzM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAy\nM7NM8MRYMxto3rY8OxyQzGxgedvybMldl52k35X095J+JGmnpJA0r8myh0haK+lpSZOl93hbd2ts\nZlnlbcuzJXcBCTgWeD+wHbi7xbJfAz4CXAycCjwN3C7pxFRraGa54G3LsyWPAemfI+LVEfHHwA3N\nFpJ0AvBnwPkRcVVE3EES2J4CLu1OVc0sy7xtebbkbgwpIva2WfQ0YAq4vuK9dku6Dlgl6eCI2JVG\nHc2sty5a/zDX3v8r9kQwJPEfTzqay5cf37DcymUL9htDAu+T1E+5C0gdWAQ8ERE7q45vBg4i6Qrc\n3PNamVlHLlr/MNfc99Qrz/dEcM19T3HNfU8x1iBrzvskZUseu+zaNZtk3KnatorXzSxnvn3/U3Vf\nK2fNrd80Ufec5YvHuGfVKXzhrGQo+fzrH2TJmg0zlrHuGKSA1BZJKyRtlLRx69at/a6OmVVYv2mC\nvTHzOc1kza3fNMHKGx5iYsckQRLIVt7wkINSjw1SQNoOHFbjeLlltK3Ga0TEuogYj4jxI444omuV\nM7PWNZue3Shr7pKbNzNVFdmm9gaX3Oxe/F4apIC0GZgvaVbV8YXAy8Djva+SmXWi2fTsRllzOyan\nWjpu3TFIAekWYBh4X/mApAOBs4AfOMPOLH+aSc921lx+5DIgSTpT0pnAG0uH3lU69vbS63Ml7ZZ0\ncblMRGwiSfn+oqQPS3oHcB0wH/hMjz+CmaVg5bIFjAwP7Xds+ABx2KxhBIyNjrD69OMbZs0dNmu4\npePWHXlN+66eEPvl0s8fAksBAUNMD7jnAX8LXA6MAg8BfxQRP+laTc2sa9JK2/7Muxex8jsPMbVn\n3zjS8JD4zLsXpVpfm5kiGqSo2CvGx8dj48aN/a6GmXWBV/3uHkkPRMR4o/Py2kIyM0vV8sVjDkB9\n5oBkZpnVz1aLW0y954BkZpnUz72KvE9Sf+Qyy87Miq+fexV5n6T+cEAys0zq515F3iepPxyQzCyT\n+rlXkfdJ6g8HJDPLpFqTXnu16kI/f/cgc1KDmWVSP/cq8j5J/eGJsS3wxFgzs9Y1OzHWXXZmZpYJ\n7rIzs4HmCbDZ4YBkZgPLE2CzxQHJzAbWTBNgWw1Ibml1zgHJzGZU5BttWhNg3dJKh5MazKyu8o12\nYsckwb4b7fpNE/2uWirSmgDb6VJD6zdNsGTNBuavupUlazYU5vq2ygHJzOoq+ppuaU2A7aSlVfSg\n3wp32ZlZXUVf0y2tCbBHjY4wUeOaNNPSahT0i9pdWosDkpnVNdONtihjS2lszLdy2YL9xpCg+ZZW\nveBebikN0riUu+zMrK56XVonH3eEu5kqLF88xurTj2dsdAQBY6MjrD79+KYCR71W1JBU6O7SWtxC\nMrO66nVppZkuXRTttrTqta6qr29ZUbpLa3FAMrMZ1brRnn/9gzXPLfLNsltmCvrtjkvllQOSmbWs\nk0F8m65e66rdcam88hiSmbXM+wV1XyfjUnnlFpKZtcz7BfVGGhmAeeKAZGZtGbSbpXWfu+zMzCwT\nHJDMzCwTchmQJB0t6TuSnpX0nKQbJc1psmzUeZzY7XqbmXWqyAux5m4MSdIsYAOwCzgXCOBy4E5J\nb4iIF5t4m6uBK6uOPZZmPc3M0lb0bS5yF5CAjwDHAAsi4nEAST8F/g/wF8AVTbzHRETc170qmpml\nr+grZOSxy+404L5yMAKIiCeAe4D39K1WZmZdVvTV1/MYkBYBj9Q4vhlY2OR7fFTSLkk7JW2Q9Nb0\nqmdWDEUeq8irtDYUzKo8BqTZwPYax7cBhzVR/hrgr4B3AiuAfwNskLS01smSVkjaKGnj1q1b26ux\nWc5407hsKvoKGXkcQ+pIRHyg4undkm4iaXFdBkxrKUXEOmAdwPj4ePSkkmZ9VvSxirzqZIWMPOxf\nlceAtJ3aLaF6LacZRcTzkm4F/rzTipkVRdHHKvKsnRUy8pKdl8cuu80k40jVFgI/63FdzAqp6GMV\ng6bRNulZkceAdDPwZknHlA9ImgcsKb3WEkmvAk4FfpxS/cxyr+hjFYMmLy3ePAakq4AngZskvUfS\nacBNwK+omOwqaa6k3ZIurjh2gaSvSjpL0lJJ55Kki78G+HRPP4VZhg3i1gdFlpcWb+7GkCLiRUmn\nAF8AvgkIuAP4RES8UHGqgCH2D7pbgPcCZwK/AzxHEpA+FBFuIZlV8GrexVFvm/SstXhzF5AAIuIp\n4IwG5zxJEpQqj90C3NK9mpmZZU9e9q/KZUAys8bykOZrvZOHFq8DklkB5SXN16xSHpMazKyBvKT5\nmlVyQDIroLyk+ZpVckAyK6C8pPmaVXJAMisgT2y1anlYvd1JDWYFlJc0X+uNvCS5OCCZFVQe0nyt\nN/Kyeru77MzMCi4vSS4OSGZmBZeXJBcHJDOzgstLkosDkplZwS1fPMYZbxxjSMnynkMSZ7wxe2OM\nTmowKyivZWdl6zdN8N0HJtgTAcCeCL77wATjc2dn6jvhFpJZAZXTfCd2TBLsS/PN4twT6768LCXl\ngGRWQHm5AVlv5CXLruUuO0mzgAXAkUAAW4EtEbEz5bqZWZvycgOy3jhqdISJGv/tc5llJ+kwSedL\nuhfYDmwEbgO+X/r3dkn3SvqEpMO6V10za8borOGax7N2A7LeyEuW3YwtJEm/A/wN8FfAISRbgH8L\n+DnwW5IdWWcDxwJvBq4APifpvwGXR8Sz3au6mdWyftMEL7y0e9rx4SFl7gZkvZGXpaQaddn9HNgF\nrAauiYgnZjpZ0jHAB4AVwHnA4WlU0syat/b2LUztjWnHDz3owMzdgKx38rCUVKOAdClwZUTsaubN\nIuIXwGclrQH+stPKmVnr6o0TPTs51eOamLVmxjGkiPivzQajqnK7IuJL7VfLzNqVl2VizKqlnvZd\nGncysz7JywC2WbWWApKkOyS9ZobXlwAPdlwrM2vb8sVjrD79eMZGRxAwNjrC6tOPz/z4gVmr85D+\nAHhI0nkRcVv5oCQBF5Fk5D2dYv3MrA15GMA2q9Zql91JwDbgFklXSBqWNAZsAD4L3AqcmHIdzcxs\nALTUQoqIn0r6PeAfgE8A7wCOAg4FPhYRX06/imZmNghaTmqIiEmSlO57gONJJsZe0MtgJOloSd+R\n9Kyk5yTdKGlOk2UPkbRW0tOSJiX9SNLbul1ns0rrN02wZM0G5q+6lSVrNnjRUzPaCEiSXgvcSzKe\n9C3gKeCLkv6mNJbUVaW19DYAxwHnkkzEfR1wp6RDm3iLrwEfAS4GTiUZ87pdkrsarSe8ErdZba1m\n2Z0N/IRkqaA/jYgPkIwZ3UIyhnSHpH+bei339xHgGGB5RKyPiJuA04C5wF/MVFDSCcCfAedHxFUR\ncQfwfpKgeml3q22W8ErcZrW12kL6JvAzYHFE3AAQEc9GxBkk692dBDyUbhWnOQ24LyIeLx8oLWl0\nD/CeJspOAddXlN0NXAcsk3Rw+tU1259X4jarrdWAtBZ4a0Q8Wf1CRHyVJCD9Swr1mski4JEaxzcD\nC5so+0SNrTI2AweRtPzMusorKZjV1lJAiohPlVoU9V5/BHhTx7Wa2WySLTCqbQMabX0xU9ny62Zd\n5ZUUzGpreYO+RiLipbTfs58krSBZvZw5c5pK5DObUatbAazfNJH5bQPM0tBoP6TLgLUR8Vwrbypp\nlCQV/KJOKlfHdmq3hOq1fqrLzq1TFva1lF4REeuAdQDj4+PT1/Q3a0OzKymUM/LKSRDljLzye5gV\nSaMuu3OAJyV9vpShNiNJ45K+BDxBks3WDZtJxoKqLSRJuGhUdn4pdby67MvA49OLmPWPM/JskDTq\nsjsO+GvgAuB8Sb8Bfkyycd829u0Y+zqShIbDSVoha4AvdqnONwOfl3RMaf8lJM0DlgCrGpQtp6e/\nD/hGqeyBwFnAD9rZasOsm5yRZ4NkxoBUukF/TtIVwNnAmSTLBVWnVz8H3A3cAFzf5Rv7VcDHgJsk\nXQQEcBnwK+DK8kmS5pIEzksj4tLS59kk6XqSibzDJC25jwLzST6fWaYcNTrCRI3g44w8K6IZu+wk\nfV3SSRHxUkR8jWQr82NJJqaeBPw+yc18dkS8OyL+Z7dbGRHxInAK8BjJvKhvkQSWUyLihcrqA0NM\n/4znAf8DuJxkMdijgT+KiJ90s95m7XBGng0SRdQfp5e0FzgnIr5der6n9PzaHtUvU8bHx2Pjxo39\nroYNGGfZWd5JeiAixhud12gM6Rng1ZXvW3qYWY94byPrh378IdQoIN0LXFRaSbucUn26pJlWNIiI\nuCyV2pmZWc/1a7pBoy67eSTZaP+epGUUNG4hRUQMNTgnl9xlZ2aDYMmaDTWTacZGR7hn1Sktv18q\nXXalNeveLukg4DXAkyQb893Uco3MzCwX+jXdoKmlgyLiZeApSd8A7o+IX3a1VmZm1jf9mm7Q6uKq\n50XE/d2qjJmZ9V+/phukvriqmZnlW6sLAKfFAcnMzKbpx3SDVjfoMzMz6woHJDMzywQHJDMzywQH\nJDMzywQHJDMzywQHJDMzywQHJDMzywQHJDMzywQHJDMzywQHJDMzywQHJDMzywQHJDMzywQvrmqW\nsvWbJnq+SrJZETggmaVo/aYJLrzxYSan9gAwsWOSC298GMBByawBd9mZpWjt7VteCUZlk1N7WHv7\nlj7VyCw/3EIy61BlF13UOefXNbaDNrP9OSCZdaC6i66eo0ZHelQjs/xyl51ZB2p10VUbGR5i5bIF\nPaqRWX65hWTWgZm64gTOsjNrQe5aSJIOkHShpCclvSTpIUlnNFn2aklR4/HFbtfbiqleV9zY6AhP\nrPkT7ll1ioORWZNyF5CAy4BLgH8A3gXcB9wg6Y+bLL8VeEvV4wvpV9MGwcplCxgZHtrvmLvozNqT\nqy47SUcCFwBrIuLzpcN3SjoWWAPc1sTbvBwR93WrjjZYyq0fT4Q161yuAhKwDDgIuKbq+DXA1yXN\nj4gnel+txjx7v7iWLx7zf0uzFOSty24RsAt4vOr45tLPhU28x5GSnpG0W9Jjkj4laahxsfaVU4Mn\nSvNUyrP312+a6OavNTPLlbwFpNnAjoionn+4reL1mTwI/DXwfuA04IfAauDKNCtZzbP3zcwa62uX\nnaR3Av/UxKk/jIilnf6+iKjOprtN0gvAxyWtiYjqlheSVgArAObMmdPW762XGuzZ+2Zm+/R7DOle\n4PVNnLez9HM7MCpJVa2kcstoG627FvgE8CamdwUSEeuAdQDj4+P1VoaZ0VGjI0zUCD6evW9mtk9f\nA1JE7AQebaHIZuBg4LXsHzzKY0c/S6lqqVq5bMG05WUapQY7CcLMBk3expD+EZgCzq46fg7wSJsZ\ndmcDAfy4w7rVtXzxGKtPP56x0RFEMmly9enH1w0wToIws0HU7y67lkTE/5N0BXChpOeBnwBnAaeQ\nJCm8QtIdwNyIOLb0fC7wDeDbwC+AEeC9wAeBKyPi592seyupwTMlQbiVZGZFlauAVPJp4AXg48Br\ngC3A+yPie1XnDbH/53se2FEq/2pgL0l34X8GvtzlOrfESRBmNog0PYPa6hkfH4+NGzd2/fcsWbOh\nZhLEYbOGmXXQgR5XMrNckfRARIw3Oi9vY0gD4eTjjqh5/NnJKY8rmVlhOSBl0J2Pbq15fG9VY9aT\na82sSByQMqiVsSKPK5lZUTggZVArE2Y9udbMisIBKYNq7bEzfIAYHtJ+x7zvjpkVSR7Tvguv3h47\ntY45y87MisJp3y3oVdq3mVmRNJv27RaSDQyvD2iWbQ5IOeWba2vK6wOWl2Qqz+MCfN3MMsJJDTnk\nxVdb500SzbLPASmHfHNtndcHNMs+B6Qc8s21dfXma3kel1l2OCDlkG+u063fNMGSNRuYv+pWlqzZ\nMK37stbcLs/jMssWB6Qc8s11f82MqbW6SaKZ9Z7nIbUgS/OQnGW3T73tOkZHhjn0YG/XYdZvnodU\ncK3sQFt09cbOdkxOsWNyCnCat1keuMvOcq/ZsTNnIpplmwOS5V6tMbV6nIloll3usrPcq7UY7c6X\nd7N959S0cwc5E9Es6xyQLFPaTdaoHlOrXioIBjsT0SwPHJAsM9Jcb658/iU3b34lseGQYfdQm2WZ\nA9IA6EaKeDfec6Ylkdp97127977y7+07p5xpZ5ZhDkgF141Vrtt9z0ZBLO0lkboR4Myse9yHUXDd\nWIi1nfdsZjWFtJdE8pp/ZvnigFRw3bgpt/OezQSxtJdE8pp/ZvnigFRw3bgpt/OezQSxtNeb85p/\nZvniMaSCW7lsQerpz+2851GjIzXXm6sOYmkuiVRrfpLXszPLrtwFJEmfBE4GxoHXAJ+NiEtaKL8c\n+AzweuBfgKuA1RGxZ8aCOdXKTbnZzLl2bvTdCIzN8Jp/ZvmRu4AEfAR4DlgP/GUrBSUtA74LfA34\nJLAY+Bzwr4FPpVvN7Gjmptxq5lyrN3q3VsyskdxtPyHpgIjYK+lAYIoWWkiSNgHPRcTbK45dDFwE\nzImI38xUPkvbT6St3hYOY6Mj3LPqlD7UyMyKotntJ3KX1BARexufNZ2ko4ETgWuqXvomMAy8q8Oq\n5ZpTpM2s3/LYZdeuRaWfj1QejIgnJO0EFva+StnRbNJBp7yxoJnVk7sWUgdml35ur/Ha9orXB1Iv\nUqRrTY49//oHmbfqVpas2bDfJFkzGzx9DUiS3ikpmnjc1cc6rpC0UdLGrVu39qsaXZf2HKBaak2O\nLY9g1lq5wcwGS7+77O4lSb9uZGcKv6vcMjqsxmuHAdtqFYqIdcA6SJIaUqhHZnU7RbrReJTXmTMb\nbH0NSBGxE3i0R79uc+nnIuBH5YOS5gGzgJ/1qB4Dq944VaWJHZMsWbPBY0xmA2hgxpAi4ingIeDs\nqpfOIUkf/37PKzVgTj7uiIbnCGZcgNXMiqvfXXYtkzQOzGNfMF0o6czSv28rtbqQdAcwNyKOrSj+\nX4DvSboSuJZkYuxFwJcazUGy6VrNmLvz0ZnH4MS+MaUyd+OZDY7cBSTgY8C5Fc/fV3oAzAeeLP17\niKrPFxG3lYLXZ4APkiwd9Dngb7tX3WJqZ0+kmcaQxmbozvNcKLPBkLsuu4j4YESozuPJivOWRsS8\nGuVvjIgTIuLgiJgTEZcWdR27bmpnT6R6c5rKq0GMebsIs4GWu4Bk2dDOyg6N5jp5uwizwZbHLjvL\ngHZWdmi0wKoXYDUbbLlbXLWfiry4aquqx5Agac2kPZnWzPKv2cVV3UKyttRqzZx83BGsvX0L51//\noFs3ZtYyByRrW+XKDu1k3ZmZVXJSg6Winaw7M7NKDkiWCu+nZGadckCyVNTLrvMcIjNrlgOSpcJz\niMysU05qsFR4DpGZdcoByVLT7f2UzKzY3GVnZmaZ4IBkZmaZ4IBkZmaZ4IBkZmaZ4IBkZmaZ4IBk\nZmaZ4O0nWiBpK/DLftcjZw4Hnul3JQrA1zEdvo7paPU6zo2IIxqd5IBkXSVpYzP7oNjMfB3T4euY\njm5dR3fZmZlZJjggmZlZJjggWbet63cFCsLXMR2+junoynX0GJKZmWWCW0hmZpYJDkiWGkkHSLpQ\n0pOSXpL0kKQzmix7taSo8fhit+vdL5KOlvQdSc9Kek7SjZLmNFn2EElrJT0taVLSjyS9rdt1zqIO\nr2Ot71xIOrHb9c4aSb8r6e9L36Wdpeswr8myqXwfvf2Epeky4ALg08ADwJ8CN0g6NSJua6L8VuC0\nqmNPp1vFbJA0C9gA7ALOBQK4HLhT0hsi4sUGb/E14E+AlcAvgP8E3C7pLRHxYPdqni0pXEeAq4Er\nq449lmY9c+JY4P0k/+/eDfyHFsqm832MCD/86PgBHElyU/hs1fE7gJ82Uf5q4P/2+3P08Hp9HNgD\nHFtxbD6wG/hkg7InkNx4z6s4diCwBbi5358tL9exdG4Al/f7c2ThARxQ8e8Pl67NvCbKpfZ9dJed\npWUZcBBwTdXxa4DjJc3vfZUy7TTgvoh4vHwgIp4A7gHe00TZKeD6irK7geuAZZIOTr+6mdXJdbQK\nEbG3zaKpfR8dkCwti0haSI9XHd9c+rmwifc4UtIzknZLekzSpyQNpVrL7FgEPFLj+GYaX6tFwBMR\nsbNG2YNIul4GRSfXseyjknaVxk02SHpretUbCKl9Hz2GZGmZDeyIUnu9wraK12fyIEnf9WbgEOC9\nwGrgdSTdB0UzG9he4/g24LAOypZfHxSdXEdIWvDfA34NzCUZA9kg6Q8j4q60KllwqX0fHZCsJknv\nBP6piVN/GBFLO/19EVGdTXebpBeAj0taU9klY5aWiPhAxdO7Jd1E0uK6DHBLqccckKyee4HXN3Fe\nuZm+HRiVpKpWUvmvo2207lrgE8CbmN4VmHfbqf0XfL2/NqvLzq1TFtq71nnVyXWcJiKel3Qr8Oed\nVmyApPZ9dECymkr9wY+2UGQzcDDwWvYPHuV+/J+lVLWi2EzS915tIY2v1WbgvZJmVfXbLwRepnjB\neyadXEdLR2rfRyc1WFr+kSTT5uyq4+cAj5Qyn1p1Nkk66Y87rFsW3Qy8WdIx5QOlSYhLSq/N5BZg\nGHhfRdkDgbOAH0TErrQrm2GdXMdpJL0KOJVifue6Jb3vY79z3/0ozgNYA7wEfBJYCnwF2AucWnXe\nHcDjFc/nAncBK4B3Au8Gvl4q+5V+f64uXatDSf5yfJgkPfk04CGSSYX/qura7AYurip/HUlXyYeB\ndwDfKV373+v3Z8vLdSSZxP3V0o1zKcnE2odJ/qp/a78/W5+u55mlx1dI/hj8aOn52+tdx0jx+9j3\nC+BHcR7AEHARya66u4CfAmfWOO8u4MmK57OB9aVyL5GMS/0E+BgVk/WK9gDmAN8FngOeL12DeVXn\nzCvdGC6pOj4CXAH8pnTN7geW9vsz5ek6lv7wuYdk59Mp4Lckrarf7/dn6uO1jDqPu+pdx9LxVL6P\nXu3bzMwywWNIZmaWCQ5IZmaWCQ5IZmaWCQ5IZmaWCQ5IZmaWCQ5IZmaWCQ5IZmaWCQ5IZmaWCQ5I\nZmaWCQ5IZmaWCQ5IZjkk6UBJ90h6UdJxVa+tkBSSLu1X/cza4bXszHJK0lySrd9/CZwUEbskLQL+\nN8l28EsjYk8/62jWCreQzHIqIn4JfAg4Afg7SSPA9SSrLZ/tYGR54xaSWc5J+jLJvjX3An8AnBER\nN/a3Vmatc0AyyzlJhwCPkGwff1VErOhzlcza4i47s/w7gWSTOoB/V9o+2ix3HJDMckzSq4BrSXY9\n/TTwFuCzfa2UWZv8l5RZvq0D5gJ/GBEbJC0GVkn6XxFxZ5/rZtYSjyGZ5ZSkDwH/HfhcRHy6dGyU\nJBV8GHhDRPy2j1U0a4kDklkOlSbDPkASfN4eEbsrXnsL8M/A9yPitD5V0axlDkhmZpYJTmowM7NM\ncEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NMcEAyM7NM+P9K\nKK1Z9m5BbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab41d90f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X, Y)\n",
    "plt.xlabel('x', fontsize=18)\n",
    "plt.ylabel('f(x)', fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network's weights (called `var` here) are initialized with values sampled from a normal distribution. We use 4 layers; performance has been found to plateau at around 6 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02206137, -0.01654351,  0.12153856, -0.01260461,  0.00548049,\n",
       "         0.07912406, -0.04546162],\n",
       "       [-0.02958183,  0.00938016, -0.0164935 , -0.05963823, -0.01024383,\n",
       "        -0.01794145,  0.03017358],\n",
       "       [-0.08323943, -0.03500895,  0.05756955,  0.09286655, -0.07555898,\n",
       "         0.03224238, -0.04903039],\n",
       "       [-0.04284266, -0.04359396, -0.0211254 ,  0.04982199,  0.03562106,\n",
       "         0.00295721, -0.01816554]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers = 4\n",
    "np.random.seed(5)\n",
    "var_init = 0.05 * np.random.randn(num_layers, 7)\n",
    "\n",
    "var_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Adam optimizer, we update the weights for 150 steps (this takes some time). To get a good result, up to 500 steps are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 0.4903563 \n",
      "Iter:     2 | Cost: 0.4617620 \n",
      "Iter:     3 | Cost: 0.4367777 \n",
      "Iter:     4 | Cost: 0.4135471 \n",
      "Iter:     5 | Cost: 0.3911694 \n",
      "Iter:     6 | Cost: 0.3691356 \n",
      "Iter:     7 | Cost: 0.3471503 \n",
      "Iter:     8 | Cost: 0.3250655 \n",
      "Iter:     9 | Cost: 0.3028538 \n",
      "Iter:    10 | Cost: 0.2806003 \n",
      "Iter:    11 | Cost: 0.2584973 \n",
      "Iter:    12 | Cost: 0.2368399 \n",
      "Iter:    13 | Cost: 0.2160133 \n",
      "Iter:    14 | Cost: 0.1964712 \n",
      "Iter:    15 | Cost: 0.1787017 \n",
      "Iter:    16 | Cost: 0.1631813 \n",
      "Iter:    17 | Cost: 0.1503201 \n",
      "Iter:    18 | Cost: 0.1404050 \n"
     ]
    }
   ],
   "source": [
    "opt = AdamOptimizer(0.01, beta1=0.9, beta2=0.999)\n",
    "\n",
    "var = var_init\n",
    "for it in range(150):\n",
    "    var = opt.step(lambda v: cost(v, X, Y), var)\n",
    "    \n",
    "    print(\"Iter: {:5d} | Cost: {:0.7f} \".format(it + 1, cost(var, X, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we collect the predictions of the trained model for 50 values in the range $[-1,1]$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(-1, 1, 50)\n",
    "predictions = [quantum_neural_net(var, x=x_) for x_ in x_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and plot the shape of the function that the model has \"learned\" from the noisy data (green dots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X, Y)\n",
    "plt.scatter(x_pred, predictions, color='green')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.tick_params(axis='both', which='major')\n",
    "plt.tick_params(axis='both', which='minor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has learned to smooth the noisy data.\n",
    "\n",
    "In fact, we can use PennyLane to look at typical functions that the model produces without being trained at all. The shape of these functions varies significantly with the variance hyperparameter for the weight initialization. \n",
    "\n",
    "Setting this hyperparameter to a small value produces almost linear functions, since all quantum gates in the variational circuit approximately perform the identity transformation in that case. Larger values produce smoothly oscillating functions with a period that depends on the number of layers used (generically, the more layers, the smaller the period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = 1.\n",
    "\n",
    "plt.figure()\n",
    "x_pred = np.linspace(-2, 2, 50)\n",
    "for i in range(7):\n",
    "    rnd_var = variance * np.random.randn(num_layers, 7)\n",
    "    predictions = [quantum_neural_net(rnd_var, x=x_) for x_ in x_pred]\n",
    "    plt.plot(x_pred, predictions, color='black')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.tick_params(axis='both', which='major')\n",
    "plt.tick_params(axis='both', which='minor')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
