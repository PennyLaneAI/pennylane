{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nQuantum Generative Adversarial Network\n======================================\n\nThis demo constructs a Quantum Generative Adversarial Network (QGAN)\n(`Lloyd and Weedbrook\n(2018) <https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.040502>`__,\n`Dallaire-Demers and Killoran\n(2018) <https://journals.aps.org/pra/abstract/10.1103/PhysRevA.98.012324>`__)\nusing two subcircuits, a *generator* and a *discriminator*. The\ngenerator attempts to generate synthetic quantum data to match a pattern\nof \u201creal\u201d data, while the discriminator, tries to discern real data from\nfake data. The gradient of the discriminator\u2019s output provides a\ntraining signal for the generator to improve its fake generated data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n~~~~~~~\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# As usual, we import PennyLane, the PennyLane-provided version of NumPy,\n# and an optimizer.\n\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom pennylane.optimize import GradientDescentOptimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also declare a 3-qubit device.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit\", wires=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classical and quantum nodes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn classical GANs, the starting point is to draw samples either from\nsome \u201creal data\u201d distribution, or from the generator, and feed them to\nthe discriminator. In this QGAN example, we will use a quantum circuit\nto generate the real data.\n\nFor this simple example, our real data will be a qubit that has been\nrotated (from the starting state $\\left|0\\right\\rangle$) to some\narbitrary, but fixed, state.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def real(phi, theta, omega):\n    qml.Rot(phi, theta, omega, wires=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the generator and discriminator, we will choose the same basic\ncircuit structure, but acting on different wires.\n\nBoth the real data circuit and the generator will output on wire 0,\nwhich will be connected as an input to the discriminator. Wire 1 is\nprovided as a workspace for the generator, while the discriminator\u2019s\noutput will be on wire 2.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generator(w):\n    qml.RX(w[0], wires=0)\n    qml.RX(w[1], wires=1)\n    qml.RY(w[2], wires=0)\n    qml.RY(w[3], wires=1)\n    qml.RZ(w[4], wires=0)\n    qml.RZ(w[5], wires=1)\n    qml.CNOT(wires=[0, 1])\n    qml.RX(w[6], wires=0)\n    qml.RY(w[7], wires=0)\n    qml.RZ(w[8], wires=0)\n\n\ndef discriminator(w):\n    qml.RX(w[0], wires=0)\n    qml.RX(w[1], wires=2)\n    qml.RY(w[2], wires=0)\n    qml.RY(w[3], wires=2)\n    qml.RZ(w[4], wires=0)\n    qml.RZ(w[5], wires=2)\n    qml.CNOT(wires=[1, 2])\n    qml.RX(w[6], wires=2)\n    qml.RY(w[7], wires=2)\n    qml.RZ(w[8], wires=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create two QNodes. One where the real data source is wired up to the\ndiscriminator, and one where the generator is connected to the\ndiscriminator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev)\ndef real_disc_circuit(phi, theta, omega, disc_weights):\n    real(phi, theta, omega)\n    discriminator(disc_weights)\n    return qml.expval(qml.PauliZ(2))\n\n\n@qml.qnode(dev)\ndef gen_disc_circuit(gen_weights, disc_weights):\n    generator(gen_weights)\n    discriminator(disc_weights)\n    return qml.expval(qml.PauliZ(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cost\n~~~~\n\nThere are two ingredients to the cost here. The first is the probability\nthat the discriminator correctly classifies real data as real. The\nsecond ingredient is the probability that the discriminator classifies\nfake data (i.e., a state prepared by the generator) as real.\n\nThe discriminator\u2019s objective is to maximize the probability of\ncorrectly classifying real data, while minimizing the probability of\nmistakenly classifying fake data.\n\nThe generator\u2019s objective is to maximize the probability that the\ndiscriminator accepts fake data as real.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def prob_real_true(disc_weights):\n    true_disc_output = real_disc_circuit(phi, theta, omega, disc_weights)\n    # convert to probability\n    prob_real_true = (true_disc_output + 1) / 2\n    return prob_real_true\n\n\ndef prob_fake_true(gen_weights, disc_weights):\n    fake_disc_output = gen_disc_circuit(gen_weights, disc_weights)\n    # convert to probability\n    prob_fake_true = (fake_disc_output + 1) / 2\n    return prob_fake_true  # generator wants to minimize this prob\n\n\ndef disc_cost(disc_weights):\n    cost = prob_fake_true(gen_weights, disc_weights) - prob_real_true(disc_weights)\n    return cost\n\n\ndef gen_cost(gen_weights):\n    return -prob_fake_true(gen_weights, disc_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimization\n~~~~~~~~~~~~\n\nWe initialize the fixed angles of the \u201creal data\u201d circuit, as well as\nthe initial parameters for both generator and discriminator. These are\nchosen so that the generator initially prepares a state on wire 0 that\nis very close to the $\\left| 1 \\right\\rangle$ state.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "phi = np.pi / 6\ntheta = np.pi / 2\nomega = np.pi / 7\nnp.random.seed(0)\neps = 1e-2\ngen_weights = np.array([np.pi] + [0] * 8) + np.random.normal(scale=eps, size=[9])\ndisc_weights = np.random.normal(size=[9])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We begin by creating the optimizer:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "opt = GradientDescentOptimizer(0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the first stage of training, we optimize the discriminator while\nkeeping the generator parameters fixed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for it in range(50):\n    disc_weights = opt.step(disc_cost, disc_weights)\n    cost = disc_cost(disc_weights)\n    if it % 5 == 0:\n        print(\"Step {}: cost = {}\".format(it + 1, cost))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the discriminator\u2019s optimum, the probability for the discriminator to\ncorrectly classify the real data should be close to one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(prob_real_true(disc_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For comparison, we check how the discriminator classifies the\ngenerator\u2019s (still unoptimized) fake data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(prob_fake_true(gen_weights, disc_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the adverserial game we have to now train the generator to better\nfool the discriminator (we can continue training the models in an\nalternating fashion until we reach the optimum point of the two-player\nadversarial game).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for it in range(200):\n    gen_weights = opt.step(gen_cost, gen_weights)\n    cost = -gen_cost(gen_weights)\n    if it % 5 == 0:\n        print(\"Step {}: cost = {}\".format(it, cost))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the optimum of the generator, the probability for the discriminator\nto be fooled should be close to 1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(prob_fake_true(gen_weights, disc_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the joint optimum the overall cost will be close to zero.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(disc_cost(disc_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The generator has successfully learned how to simulate the real data\nenough to fool the discriminator.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}