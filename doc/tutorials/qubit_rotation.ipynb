{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qubit rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates the very basic working principles of openqml for qubit-based backends. We only look at a single quantum function consisting of a single-qubit circuit. The task is to optimize two rotation gates in order to flip the qubit from state $|0\\rangle$ to state $|1\\rangle$. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note:: This tutorial requires the `OpenQML-PQ plugin <https://github.com/XanaduAI/openqml-pq>`_, in order to access `Project Q <https://github.com/ProjectQ-Framework/ProjectQ>`_ devices using OpenQML. It can be installed via pip: ``pip install openqml-pq``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import OpenQML, as well as OpenQML's version of NumPy. This allows us to automatically compute gradients for functions that manipulate NumPy arrays, including quantum functions. We call this NumPy version `onp` in case we need it alongside the original version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openqml as qm\n",
    "from openqml import numpy as np\n",
    "from openqml.optimize import GradientDescentOptimizer, AdagradOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a projecq simulator as a \"device\" to run the quantum node. We only need a single quantum wire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = qm.device('projectq.simulator', wires=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the quantum function\n",
    "\n",
    "We define a quantum function called \"circuit\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qm.qfunc(dev1)\n",
    "def circuit(variables):\n",
    "    \n",
    "    qm.RX(variables[0], [0])\n",
    "    qm.RY(variables[1], [0])\n",
    "    \n",
    "    return qm.expectation.PauliZ(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses openqml to run the following quantum circuit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/rotation_circuit.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with a qubit in the ground state, \n",
    "\n",
    "$$ |0\\rangle = \\begin{pmatrix}1 \\\\ 0 \\end{pmatrix}, $$\n",
    "\n",
    "we first rotate the qubit around the x-axis by \n",
    "$$R_x(w_0) = e^{-iw_0 X /2} = \n",
    "\\begin{pmatrix} \\cos \\frac{w_0}{2} &  -i \\sin \\frac{w_0}{2} \\\\  \n",
    "                -i \\sin \\frac{w_0}{2} &  \\cos \\frac{w_0}{2} \n",
    "\\end{pmatrix}, $$ \n",
    "               \n",
    "and then around the y-axis by \n",
    "$$ R_y(w_1) = e^{-i w_1 Y/2} = \n",
    "\\begin{pmatrix} \\cos \\frac{w_1}{2} &  - \\sin \\frac{w_1}{2} \\\\  \n",
    "                \\sin \\frac{w_1}{2} &  \\cos \\frac{w_1}{2} \n",
    "\\end{pmatrix}. $$ \n",
    "\n",
    "After these operations the qubit is in the state\n",
    "\n",
    "$$ | \\psi \\rangle = R_y(w_0) R_x(w_1) | 0 \\rangle $$\n",
    "\n",
    "Finally, we measure the expectation $\\langle\\psi|Z|\\psi\\rangle$ of the Pauli-Z operator \n",
    "$$Z = \n",
    "\\begin{pmatrix} 1 &  0 \\\\  \n",
    "                0 & -1 \n",
    "\\end{pmatrix}. $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the circuit parameters $w_1$ and $w_2$, the output expectation lies between $1$ (if $\\left|\\psi\\right\\rangle=\\left|0\\right\\rangle$) and $-1$ (if $|\\psi\\rangle=|1\\rangle$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a cost. Here, the cost is directly the expectation of the PauliZ measurement, so that the cost is trivially the output of the circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(variables):\n",
    "    return circuit(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this objective, the optimization procedure is supposed to find the weights that rotate the qubit from the ground state \n",
    "\n",
    " <img src=\"figures/bloch_before.png\" width=\"250\"> \n",
    " \n",
    " to the excited state\n",
    " \n",
    " <img src=\"figures/bloch_after.png\" width=\"250\">\n",
    " \n",
    " The rotation gates give the optimization landscape a trigonometric shape with four global minima and five global maxima.\n",
    " \n",
    " <img src=\"figures/optlandscape.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial values of the x- and y-rotation parameters $w_1, w_2$ are set to near-zero. This corresponds to identity gates, in other words, the circuit leaves the qubit in the ground state."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note:: Note that at zero exactly the gradient vanishes and the optimization algorithm will not descent from the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_init = np.array([0.01, 0.01])\n",
    "variables_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the objective at the initial point is close to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999000033332889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective(variables_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a simple [Gradient Descent Optimizer](../API/optimize.rst#openqml.optimize.GradientDescentOptimizer) and update the weights for 10 steps. The final parameters correspond to a $Z$ expectation of nearly $-1$, which means that the qubit is flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective after step     0:  0.9997750\n",
      "Objective after step     5:  0.9997750\n",
      "Objective after step    10:  0.9997750\n",
      "Objective after step    15:  0.9997750\n",
      "Objective after step    20:  0.9997750\n",
      "Objective after step    25:  0.9997750\n",
      "Objective after step    30:  0.9997750\n",
      "Objective after step    35:  0.9997750\n",
      "Objective after step    40:  0.9997750\n",
      "Objective after step    45:  0.9997750\n",
      "Objective after step    50:  0.9997750\n",
      "Objective after step    55:  0.9997750\n",
      "Objective after step    60:  0.9997750\n",
      "Objective after step    65:  0.9997750\n",
      "Objective after step    70:  0.9997750\n",
      "Objective after step    75:  0.9997750\n",
      "Objective after step    80:  0.9997750\n",
      "Objective after step    85:  0.9997750\n",
      "Objective after step    90:  0.9997750\n",
      "Objective after step    95:  0.9997750\n",
      "\n",
      "Optimized rotation angles: [ 0.01  0.01]\n"
     ]
    }
   ],
   "source": [
    "o = GradientDescentOptimizer(0.5)\n",
    "\n",
    "variables = variables_init\n",
    "for it in range(100):\n",
    "    weights = o.step(objective, variables)\n",
    "    if it % 5 == 0:\n",
    "        print('Objective after step {:5d}: {: .7f}'.format(it, objective(weights)) )\n",
    "\n",
    "print()\n",
    "print('Optimized rotation angles:', variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting at a different offset, we train another optimizer called [Adagrad](../API/optimize.rst#openqml.optimize.Adagrad), which improves on gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rotation angles: [-0.01  0.01]\n",
      "Objective after step     1:  0.7617043\n",
      "Objective after step     6:  0.0000072\n",
      "Objective after step    11:  0.0000000\n",
      "Objective after step    16:  0.0000000\n",
      "Objective after step    21:  0.0000000\n",
      "Objective after step    26: -0.0000000\n",
      "Objective after step    31: -0.0000000\n",
      "Objective after step    36: -0.0000000\n",
      "Objective after step    41: -0.0000000\n",
      "Objective after step    46: -0.0000081\n",
      "Objective after step    51: -0.0024196\n",
      "Objective after step    56: -0.3870690\n",
      "Objective after step    61: -0.9926985\n",
      "Objective after step    66: -0.9999724\n",
      "Objective after step    71: -0.9999999\n",
      "Objective after step    76: -1.0000000\n",
      "Objective after step    81: -1.0000000\n",
      "Objective after step    86: -1.0000000\n",
      "Objective after step    91: -1.0000000\n",
      "Objective after step    96: -1.0000000\n",
      "\n",
      "Optimized rotation angles: [ -3.14159265e+00   2.94207915e-11]\n"
     ]
    }
   ],
   "source": [
    "variables_init = np.array([-0.01, 0.01])\n",
    "print('Initial rotation angles:', variables_init)\n",
    "\n",
    "o = AdagradOptimizer(0.5)\n",
    "\n",
    "variables = variables_init\n",
    "for it in range(100):\n",
    "    variables = o.step(objective, variables)\n",
    "    if it % 5 == 0:\n",
    "        print('Objective after step {:5d}: {: .7f}'.format(it+1, objective(variables)) )\n",
    "\n",
    "print()\n",
    "print('Optimized rotation angles:', variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Adagrad and gradient descent find the same minimum, and, since neither has information on second order derivatives, both take a detour through a saddle point. However, Adagrad takes considerably fewer steps.\n",
    " \n",
    " <img src=\"figures/gd_vs_adag_qubit.png\" width=\"450\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
